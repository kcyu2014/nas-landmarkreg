{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Use to test the back propagation of model_search for NASBenchNet\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "from nasbench.api import ModelSpec\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "home = os.environ['HOME']\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "os.chdir(f'{home}/pycharm/automl')\n",
    "# os.chdir(f'{home}/pycharm/automl/search_policies/rnn')\n",
    "sys.path.append(f'{home}/pycharm/nasbench')\n",
    "sys.path.append(f'{home}/pycharm/automl')\n",
    "\n",
    "# !ls data/nasbench"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[0.38076125 0.76041522 0.75035755]\n32\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "from search_policies.cnn.search_space.nasbench101.model_search import *\n",
    "from search_policies.cnn.search_space.nasbench101.model import NasBenchNet as NasbenchNetOriginal\n",
    "from search_policies.cnn.search_space.nasbench101.nasbench_api_v2 import NASBench_v2\n",
    "\n",
    "nasbench = NASBench_v2('data/nasbench/nasbench_only108.tfrecord', only_hash=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "INFO:tensorflow:vertex_channels: [128, 128, 128, 128, 128, 128, 256]\n",
      "INFO:tensorflow:vertex_channels: [256, 128, 128, 128, 128, 128, 256]\n",
      "INFO:tensorflow:vertex_channels: [256, 128, 128, 128, 128, 128, 256]\n",
      "INFO:tensorflow:vertex_channels: [256, 256, 256, 256, 256, 256, 512]\n",
      "INFO:tensorflow:vertex_channels: [512, 256, 256, 256, 256, 256, 512]\n",
      "INFO:tensorflow:vertex_channels: [512, 256, 256, 256, 256, 256, 512]\n",
      "INFO:tensorflow:vertex_channels: [512, 512, 512, 512, 512, 512, 1024]\n",
      "INFO:tensorflow:vertex_channels: [1024, 512, 512, 512, 512, 512, 1024]\n",
      "INFO:tensorflow:vertex_channels: [1024, 512, 512, 512, 512, 512, 1024]\n",
      "INFO:tensorflow:vertex_channels: [128, 128, 128, 128, 128, 128, 256]\n",
      "INFO:tensorflow:vertex_channels: [256, 128, 128, 128, 128, 128, 256]\n",
      "INFO:tensorflow:vertex_channels: [256, 128, 128, 128, 128, 128, 256]\n",
      "INFO:tensorflow:vertex_channels: [256, 256, 256, 256, 256, 256, 512]\n",
      "INFO:tensorflow:vertex_channels: [512, 256, 256, 256, 256, 256, 512]\n",
      "INFO:tensorflow:vertex_channels: [512, 256, 256, 256, 256, 256, 512]\n",
      "INFO:tensorflow:vertex_channels: [512, 512, 512, 512, 512, 512, 1024]\n",
      "INFO:tensorflow:vertex_channels: [1024, 512, 512, 512, 512, 512, 1024]\n",
      "INFO:tensorflow:vertex_channels: [1024, 512, 512, 512, 512, 512, 1024]\n",
      "order dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [128, 52, 51, 51, 51, 51, 256]\n",
      "order dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [256, 52, 51, 51, 51, 51, 256]\n",
      "order dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [256, 52, 51, 51, 51, 51, 256]\n",
      "order dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [256, 103, 103, 102, 102, 102, 512]\n",
      "order dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [512, 103, 103, 102, 102, 102, 512]\n",
      "order dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [512, 103, 103, 102, 102, 102, 512]\n",
      "order dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [512, 205, 205, 205, 205, 204, 1024]\n",
      "order dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [1024, 205, 205, 205, 205, 204, 1024]\n",
      "order dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [1024, 205, 205, 205, 205, 204, 1024]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "hashs = []\n",
    "ind = 0\n",
    "for ind, (k, v) in enumerate(nasbench.hash_dict.items()):\n",
    "     if ind < 10:\n",
    "         # print(k, v)\n",
    "         hashs.append(k)\n",
    "\n",
    "_hash = hashs[0]\n",
    "_hash2 = hashs[1]\n",
    "\n",
    "input_channels = 3\n",
    "# print(nasbench.hash_to_model_spec(_hash))\n",
    "spec_1 = nasbench.hash_to_model_spec(_hash)\n",
    "spec_2 = nasbench.hash_to_model_spec(_hash2)\n",
    "\n",
    "model1 = NasbenchNetOriginal(input_channels, spec_1)\n",
    "model2 = NasbenchNetOriginal(input_channels, spec_2)\n",
    "model_search = NasBenchNetSearch(input_channels, spec_1)\n",
    "\n",
    "\n",
    "x = torch.randn(8, 3, 32, 32)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Adjacent matrix: [[0, 1, 1, 1, 1, 1, 1], [0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0]] \nOps: ['input', 'conv3x3-bn-relu', 'maxpool3x3', 'conv3x3-bn-relu', 'conv3x3-bn-relu', 'conv1x1-bn-relu', 'output']\n\nchange spec for stack0\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [128, 52, 51, 51, 51, 51, 256]\n",
      "update for  vertex_1  out shapes 52\nChange proj op vertex type , size 52\nchange vertex type conv1x1-bn-relu  size to 52\n52\nchange vertex type conv3x3-bn-relu  size to 52\n52\nupdate for  vertex_2  out shapes 51\nChange proj op vertex type , size 51\nchange vertex type conv1x1-bn-relu  size to 51\n51\nchange vertex type conv3x3-bn-relu  size to 51\n51\nupdate for  vertex_3  out shapes 51\nChange proj op vertex type , size 51\nchange vertex type conv1x1-bn-relu  size to 51\n51\nchange vertex type conv3x3-bn-relu  size to 51\n51\nupdate for  vertex_4  out shapes 51\nChange proj op vertex type , size 51\nchange vertex type conv1x1-bn-relu  size to 51\n51\nchange vertex type conv3x3-bn-relu  size to 51\n51\nupdate for  vertex_5  out shapes 51\nChange proj op vertex type , size 51\nchange vertex type conv1x1-bn-relu  size to 51\n51\nchange vertex type conv3x3-bn-relu  size to 51\n51\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [256, 52, 51, 51, 51, 51, 256]\n",
      "update for  vertex_1  out shapes 52\nChange proj op vertex type , size 52\nchange vertex type conv1x1-bn-relu  size to 52\n52\nchange vertex type conv3x3-bn-relu  size to 52\n52\nupdate for  vertex_2  out shapes 51\nChange proj op vertex type , size 51\nchange vertex type conv1x1-bn-relu  size to 51\n51\nchange vertex type conv3x3-bn-relu  size to 51\n51\nupdate for  vertex_3  out shapes 51\nChange proj op vertex type , size 51\nchange vertex type conv1x1-bn-relu  size to 51\n51\nchange vertex type conv3x3-bn-relu  size to 51\n51\nupdate for  vertex_4  out shapes 51\nChange proj op vertex type , size 51\nchange vertex type conv1x1-bn-relu  size to 51\n51\nchange vertex type conv3x3-bn-relu  size to 51\n51\nupdate for  vertex_5  out shapes 51\nChange proj op vertex type , size 51\nchange vertex type conv1x1-bn-relu  size to 51\n51\nchange vertex type conv3x3-bn-relu  size to 51\n51\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [256, 52, 51, 51, 51, 51, 256]\n",
      "update for  vertex_1  out shapes 52\nChange proj op vertex type , size 52\nchange vertex type conv1x1-bn-relu  size to 52\n52\nchange vertex type conv3x3-bn-relu  size to 52\n52\nupdate for  vertex_2  out shapes 51\nChange proj op vertex type , size 51\nchange vertex type conv1x1-bn-relu  size to 51\n51\nchange vertex type conv3x3-bn-relu  size to 51\n51\nupdate for  vertex_3  out shapes 51\nChange proj op vertex type , size 51\nchange vertex type conv1x1-bn-relu  size to 51\n51\nchange vertex type conv3x3-bn-relu  size to 51\n51\nupdate for  vertex_4  out shapes 51\nChange proj op vertex type , size 51\nchange vertex type conv1x1-bn-relu  size to 51\n51\nchange vertex type conv3x3-bn-relu  size to 51\n51\nupdate for  vertex_5  out shapes 51\nChange proj op vertex type , size 51\nchange vertex type conv1x1-bn-relu  size to 51\n51\nchange vertex type conv3x3-bn-relu  size to 51\n51\nchange spec for stack1\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [256, 103, 103, 102, 102, 102, 512]\n",
      "update for  vertex_1  out shapes 103\nChange proj op vertex type , size 103\nchange vertex type conv1x1-bn-relu  size to 103\n103\nchange vertex type conv3x3-bn-relu  size to 103\n103\nupdate for  vertex_2  out shapes 103\nChange proj op vertex type , size 103\nchange vertex type conv1x1-bn-relu  size to 103\n103\nchange vertex type conv3x3-bn-relu  size to 103\n103\nupdate for  vertex_3  out shapes 102\nChange proj op vertex type , size 102\nchange vertex type conv1x1-bn-relu  size to 102\n102\nchange vertex type conv3x3-bn-relu  size to 102\n102\nupdate for  vertex_4  out shapes 102\nChange proj op vertex type , size 102\nchange vertex type conv1x1-bn-relu  size to 102\n102\nchange vertex type conv3x3-bn-relu  size to 102\n102\nupdate for  vertex_5  out shapes 102\nChange proj op vertex type , size 102\nchange vertex type conv1x1-bn-relu  size to 102\n102\nchange vertex type conv3x3-bn-relu  size to 102\n102\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [512, 103, 103, 102, 102, 102, 512]\n",
      "update for  vertex_1  out shapes 103\nChange proj op vertex type , size 103\nchange vertex type conv1x1-bn-relu  size to 103\n103\nchange vertex type conv3x3-bn-relu  size to 103\n103\nupdate for  vertex_2  out shapes 103\nChange proj op vertex type , size 103\nchange vertex type conv1x1-bn-relu  size to 103\n103\nchange vertex type conv3x3-bn-relu  size to 103\n103\nupdate for  vertex_3  out shapes 102\nChange proj op vertex type , size 102\nchange vertex type conv1x1-bn-relu  size to 102\n102\nchange vertex type conv3x3-bn-relu  size to 102\n102\nupdate for  vertex_4  out shapes 102\nChange proj op vertex type , size 102\nchange vertex type conv1x1-bn-relu  size to 102\n102\nchange vertex type conv3x3-bn-relu  size to 102\n102\nupdate for  vertex_5  out shapes 102\nChange proj op vertex type , size 102\nchange vertex type conv1x1-bn-relu  size to 102\n102\nchange vertex type conv3x3-bn-relu  size to 102\n102\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [512, 103, 103, 102, 102, 102, 512]\n",
      "update for  vertex_1  out shapes 103\nChange proj op vertex type , size 103\nchange vertex type conv1x1-bn-relu  size to 103\n103\nchange vertex type conv3x3-bn-relu  size to 103\n103\nupdate for  vertex_2  out shapes 103\nChange proj op vertex type , size 103\nchange vertex type conv1x1-bn-relu  size to 103\n103\nchange vertex type conv3x3-bn-relu  size to 103\n103\nupdate for  vertex_3  out shapes 102\nChange proj op vertex type , size 102\nchange vertex type conv1x1-bn-relu  size to 102\n102\nchange vertex type conv3x3-bn-relu  size to 102\n102\nupdate for  vertex_4  out shapes 102\nChange proj op vertex type , size 102\nchange vertex type conv1x1-bn-relu  size to 102\n102\nchange vertex type conv3x3-bn-relu  size to 102\n102\nupdate for  vertex_5  out shapes 102\nChange proj op vertex type , size 102\nchange vertex type conv1x1-bn-relu  size to 102\n102\nchange vertex type conv3x3-bn-relu  size to 102\n102\nchange spec for stack2\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [512, 205, 205, 205, 205, 204, 1024]\n",
      "update for  vertex_1  out shapes 205\nChange proj op vertex type , size 205\nchange vertex type conv1x1-bn-relu  size to 205\n205\nchange vertex type conv3x3-bn-relu  size to 205\n205\nupdate for  vertex_2  out shapes 205\nChange proj op vertex type , size 205\nchange vertex type conv1x1-bn-relu  size to 205\n205\nchange vertex type conv3x3-bn-relu  size to 205\n205\nupdate for  vertex_3  out shapes 205\nChange proj op vertex type , size 205\nchange vertex type conv1x1-bn-relu  size to 205\n205\nchange vertex type conv3x3-bn-relu  size to 205\n205\nupdate for  vertex_4  out shapes 205\nChange proj op vertex type , size 205\nchange vertex type conv1x1-bn-relu  size to 205\n205\nchange vertex type conv3x3-bn-relu  size to 205\n205\nupdate for  vertex_5  out shapes 204\nChange proj op vertex type , size 204\nchange vertex type conv1x1-bn-relu  size to 204\n204\nchange vertex type conv3x3-bn-relu  size to 204\n204\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [1024, 205, 205, 205, 205, 204, 1024]\n",
      "update for  vertex_1  out shapes 205\nChange proj op vertex type , size 205\nchange vertex type conv1x1-bn-relu  size to 205\n205\nchange vertex type conv3x3-bn-relu  size to 205\n205\nupdate for  vertex_2  out shapes 205\nChange proj op vertex type , size 205\nchange vertex type conv1x1-bn-relu  size to 205\n205\nchange vertex type conv3x3-bn-relu  size to 205\n205\nupdate for  vertex_3  out shapes 205\nChange proj op vertex type , size 205\nchange vertex type conv1x1-bn-relu  size to 205\n205\nchange vertex type conv3x3-bn-relu  size to 205\n205\nupdate for  vertex_4  out shapes 205\nChange proj op vertex type , size 205\nchange vertex type conv1x1-bn-relu  size to 205\n205\nchange vertex type conv3x3-bn-relu  size to 205\n205\nupdate for  vertex_5  out shapes 204\nChange proj op vertex type , size 204\nchange vertex type conv1x1-bn-relu  size to 204\n204\nchange vertex type conv3x3-bn-relu  size to 204\n204\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [1024, 205, 205, 205, 205, 204, 1024]\n",
      "update for  vertex_1  out shapes 205\nChange proj op vertex type , size 205\nchange vertex type conv1x1-bn-relu  size to 205\n205\nchange vertex type conv3x3-bn-relu  size to 205\n205\nupdate for  vertex_2  out shapes 205\nChange proj op vertex type , size 205\nchange vertex type conv1x1-bn-relu  size to 205\n205\nchange vertex type conv3x3-bn-relu  size to 205\n205\nupdate for  vertex_3  out shapes 205\nChange proj op vertex type , size 205\nchange vertex type conv1x1-bn-relu  size to 205\n205\nchange vertex type conv3x3-bn-relu  size to 205\n205\nupdate for  vertex_4  out shapes 205\nChange proj op vertex type , size 205\nchange vertex type conv1x1-bn-relu  size to 205\n205\nchange vertex type conv3x3-bn-relu  size to 205\n205\nupdate for  vertex_5  out shapes 204\nChange proj op vertex type , size 204\nchange vertex type conv1x1-bn-relu  size to 204\n204\nchange vertex type conv3x3-bn-relu  size to 204\n204\nbefore conv  torch.Size([8, 128, 32, 32])\nconv weight shape torch.Size([256, 128, 1, 1])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 52, 32, 32])\nbefore conv  torch.Size([8, 52, 32, 32])\nconv weight shape torch.Size([256, 256, 3, 3])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 52, 32, 32])\nbefore conv  torch.Size([8, 128, 32, 32])\nconv weight shape torch.Size([256, 128, 1, 1])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 128, 32, 32])\nconv weight shape torch.Size([256, 128, 1, 1])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 51, 32, 32])\nconv weight shape torch.Size([256, 256, 3, 3])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 128, 32, 32])\nconv weight shape torch.Size([256, 128, 1, 1])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 51, 32, 32])\nconv weight shape torch.Size([256, 256, 3, 3])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 128, 32, 32])\nconv weight shape torch.Size([256, 128, 1, 1])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 51, 32, 32])\nconv weight shape torch.Size([256, 256, 1, 1])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 256, 32, 32])\nconv weight shape torch.Size([256, 256, 1, 1])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 52, 32, 32])\nbefore conv  torch.Size([8, 52, 32, 32])\nconv weight shape torch.Size([256, 256, 3, 3])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 52, 32, 32])\nbefore conv  torch.Size([8, 256, 32, 32])\nconv weight shape torch.Size([256, 256, 1, 1])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 256, 32, 32])\nconv weight shape torch.Size([256, 256, 1, 1])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 51, 32, 32])\nconv weight shape torch.Size([256, 256, 3, 3])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 256, 32, 32])\nconv weight shape torch.Size([256, 256, 1, 1])\n",
      "after conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 51, 32, 32])\nconv weight shape torch.Size([256, 256, 3, 3])\n",
      "after conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 256, 32, 32])\nconv weight shape torch.Size([256, 256, 1, 1])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 51, 32, 32])\nconv weight shape torch.Size([256, 256, 1, 1])\n",
      "after conv  torch.Size([8, 256, 32, 32])\n",
      "after drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 256, 32, 32])\nconv weight shape torch.Size([256, 256, 1, 1])\n",
      "after conv  torch.Size([8, 256, 32, 32])\n",
      "after drop  torch.Size([8, 52, 32, 32])\n",
      "before conv  torch.Size([8, 52, 32, 32])\nconv weight shape torch.Size([256, 256, 3, 3])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 52, 32, 32])\nbefore conv  torch.Size([8, 256, 32, 32])\nconv weight shape torch.Size([256, 256, 1, 1])\n",
      "after conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 256, 32, 32])\nconv weight shape torch.Size([256, 256, 1, 1])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 51, 32, 32])\nconv weight shape torch.Size([256, 256, 3, 3])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 256, 32, 32])\nconv weight shape torch.Size([256, 256, 1, 1])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 51, 32, 32])\nconv weight shape torch.Size([256, 256, 3, 3])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 256, 32, 32])\nconv weight shape torch.Size([256, 256, 1, 1])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 51, 32, 32])\nconv weight shape torch.Size([256, 256, 1, 1])\nafter conv  torch.Size([8, 256, 32, 32])\nafter drop  torch.Size([8, 51, 32, 32])\nbefore conv  torch.Size([8, 256, 16, 16])\nconv weight shape torch.Size([512, 256, 1, 1])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 103, 16, 16])\nbefore conv  torch.Size([8, 103, 16, 16])\nconv weight shape torch.Size([512, 512, 3, 3])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 103, 16, 16])\nbefore conv  torch.Size([8, 256, 16, 16])\nconv weight shape torch.Size([512, 256, 1, 1])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 103, 16, 16])\nbefore conv  torch.Size([8, 256, 16, 16])\nconv weight shape torch.Size([512, 256, 1, 1])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 102, 16, 16])\nbefore conv  torch.Size([8, 102, 16, 16])\nconv weight shape torch.Size([512, 512, 3, 3])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 102, 16, 16])\nbefore conv  torch.Size([8, 256, 16, 16])\nconv weight shape torch.Size([512, 256, 1, 1])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 102, 16, 16])\nbefore conv  torch.Size([8, 102, 16, 16])\nconv weight shape torch.Size([512, 512, 3, 3])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 102, 16, 16])\nbefore conv  torch.Size([8, 256, 16, 16])\nconv weight shape torch.Size([512, 256, 1, 1])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 102, 16, 16])\nbefore conv  torch.Size([8, 102, 16, 16])\nconv weight shape torch.Size([512, 512, 1, 1])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 102, 16, 16])\nbefore conv  torch.Size([8, 512, 16, 16])\nconv weight shape torch.Size([512, 512, 1, 1])\nafter conv  torch.Size([8, 512, 16, 16])\n",
      "after drop  torch.Size([8, 103, 16, 16])\nbefore conv  torch.Size([8, 103, 16, 16])\nconv weight shape torch.Size([512, 512, 3, 3])\nafter conv  torch.Size([8, 512, 16, 16])\n",
      "after drop  torch.Size([8, 103, 16, 16])\nbefore conv  torch.Size([8, 512, 16, 16])\nconv weight shape torch.Size([512, 512, 1, 1])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 103, 16, 16])\nbefore conv  torch.Size([8, 512, 16, 16])\nconv weight shape torch.Size([512, 512, 1, 1])\nafter conv  torch.Size([8, 512, 16, 16])\n",
      "after drop  torch.Size([8, 102, 16, 16])\nbefore conv  torch.Size([8, 102, 16, 16])\nconv weight shape torch.Size([512, 512, 3, 3])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 102, 16, 16])\nbefore conv  torch.Size([8, 512, 16, 16])\nconv weight shape torch.Size([512, 512, 1, 1])\n",
      "after conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 102, 16, 16])\n",
      "before conv  torch.Size([8, 102, 16, 16])\nconv weight shape torch.Size([512, 512, 3, 3])\n",
      "after conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 102, 16, 16])\nbefore conv  torch.Size([8, 512, 16, 16])\nconv weight shape torch.Size([512, 512, 1, 1])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 102, 16, 16])\nbefore conv  torch.Size([8, 102, 16, 16])\nconv weight shape torch.Size([512, 512, 1, 1])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 102, 16, 16])\n",
      "before conv  torch.Size([8, 512, 16, 16])\nconv weight shape torch.Size([512, 512, 1, 1])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 103, 16, 16])\nbefore conv  torch.Size([8, 103, 16, 16])\nconv weight shape torch.Size([512, 512, 3, 3])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 103, 16, 16])\nbefore conv  torch.Size([8, 512, 16, 16])\nconv weight shape torch.Size([512, 512, 1, 1])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 103, 16, 16])\nbefore conv  torch.Size([8, 512, 16, 16])\nconv weight shape torch.Size([512, 512, 1, 1])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 102, 16, 16])\nbefore conv  torch.Size([8, 102, 16, 16])\nconv weight shape torch.Size([512, 512, 3, 3])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 102, 16, 16])\nbefore conv  torch.Size([8, 512, 16, 16])\nconv weight shape torch.Size([512, 512, 1, 1])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 102, 16, 16])\nbefore conv  torch.Size([8, 102, 16, 16])\nconv weight shape torch.Size([512, 512, 3, 3])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 102, 16, 16])\nbefore conv  torch.Size([8, 512, 16, 16])\nconv weight shape torch.Size([512, 512, 1, 1])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 102, 16, 16])\nbefore conv  torch.Size([8, 102, 16, 16])\nconv weight shape torch.Size([512, 512, 1, 1])\nafter conv  torch.Size([8, 512, 16, 16])\nafter drop  torch.Size([8, 102, 16, 16])\nbefore conv  torch.Size([8, 512, 8, 8])\nconv weight shape torch.Size([1024, 512, 1, 1])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 205, 8, 8])\nconv weight shape torch.Size([1024, 1024, 3, 3])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 512, 8, 8])\nconv weight shape torch.Size([1024, 512, 1, 1])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 512, 8, 8])\nconv weight shape torch.Size([1024, 512, 1, 1])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 205, 8, 8])\nconv weight shape torch.Size([1024, 1024, 3, 3])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 512, 8, 8])\nconv weight shape torch.Size([1024, 512, 1, 1])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 205, 8, 8])\nconv weight shape torch.Size([1024, 1024, 3, 3])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 512, 8, 8])\nconv weight shape torch.Size([1024, 512, 1, 1])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 204, 8, 8])\nbefore conv  torch.Size([8, 204, 8, 8])\nconv weight shape torch.Size([1024, 1024, 1, 1])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 204, 8, 8])\nbefore conv  torch.Size([8, 1024, 8, 8])\nconv weight shape torch.Size([1024, 1024, 1, 1])\n",
      "after conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 205, 8, 8])\nconv weight shape torch.Size([1024, 1024, 3, 3])\n",
      "after conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 1024, 8, 8])\nconv weight shape torch.Size([1024, 1024, 1, 1])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 1024, 8, 8])\nconv weight shape torch.Size([1024, 1024, 1, 1])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\n",
      "before conv  torch.Size([8, 205, 8, 8])\nconv weight shape torch.Size([1024, 1024, 3, 3])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 1024, 8, 8])\nconv weight shape torch.Size([1024, 1024, 1, 1])\nafter conv  torch.Size([8, 1024, 8, 8])\n",
      "after drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 205, 8, 8])\nconv weight shape torch.Size([1024, 1024, 3, 3])\n",
      "after conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 1024, 8, 8])\nconv weight shape torch.Size([1024, 1024, 1, 1])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 204, 8, 8])\nbefore conv  torch.Size([8, 204, 8, 8])\nconv weight shape torch.Size([1024, 1024, 1, 1])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 204, 8, 8])\nbefore conv  torch.Size([8, 1024, 8, 8])\nconv weight shape torch.Size([1024, 1024, 1, 1])\n",
      "after conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 205, 8, 8])\nconv weight shape torch.Size([1024, 1024, 3, 3])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 1024, 8, 8])\nconv weight shape torch.Size([1024, 1024, 1, 1])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 1024, 8, 8])\nconv weight shape torch.Size([1024, 1024, 1, 1])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 205, 8, 8])\nconv weight shape torch.Size([1024, 1024, 3, 3])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 1024, 8, 8])\nconv weight shape torch.Size([1024, 1024, 1, 1])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 205, 8, 8])\nconv weight shape torch.Size([1024, 1024, 3, 3])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 205, 8, 8])\nbefore conv  torch.Size([8, 1024, 8, 8])\nconv weight shape torch.Size([1024, 1024, 1, 1])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 204, 8, 8])\nbefore conv  torch.Size([8, 204, 8, 8])\nconv weight shape torch.Size([1024, 1024, 1, 1])\nafter conv  torch.Size([8, 1024, 8, 8])\nafter drop  torch.Size([8, 204, 8, 8])\ntorch.Size([8, 10])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(spec_1)\n",
    "model_search.change_model_spec(spec_1)\n",
    "\n",
    "# print(layer0)\n",
    "y = model_search(x)\n",
    "print(y[0].size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Adjacent matrix: [[0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0]] \nOps: ['input', 'conv1x1-bn-relu', 'conv1x1-bn-relu', 'conv3x3-bn-relu', 'conv1x1-bn-relu', 'conv3x3-bn-relu', 'output']\n\nchange spec for stack0\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [128, 128, 128, 128, 128, 128, 256]\n",
      "Op key vertex_1  to out shapes 128\nMixedVertex(\n  (proj_ops): ModuleList(\n    (0): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n  )\n  (ops): ModuleDict(\n    (conv1x1-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (conv3x3-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (maxpool3x3): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n  )\n)\nproj size before  128\nproj op ???  128\nvertex type conv1x1-bn-relu  size to 128\n128\nvertex type conv3x3-bn-relu  size to 128\n128\nproj op size to  128\nOp key vertex_2  to out shapes 128\nvertex type conv1x1-bn-relu  size to 128\n128\nvertex type conv3x3-bn-relu  size to 128\n128\nproj op size to  51\nOp key vertex_3  to out shapes 128\nvertex type conv1x1-bn-relu  size to 128\n128\nvertex type conv3x3-bn-relu  size to 128\n128\nproj op size to  51\nOp key vertex_4  to out shapes 128\nvertex type conv1x1-bn-relu  size to 128\n128\nvertex type conv3x3-bn-relu  size to 128\n128\nproj op size to  51\nOp key vertex_5  to out shapes 128\nvertex type conv1x1-bn-relu  size to 128\n128\nvertex type conv3x3-bn-relu  size to 128\n128\nproj op size to  51\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [256, 128, 128, 128, 128, 128, 256]\n",
      "Op key vertex_1  to out shapes 128\nMixedVertex(\n  (proj_ops): ModuleList(\n    (0): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n  )\n  (ops): ModuleDict(\n    (conv1x1-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (conv3x3-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (maxpool3x3): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n  )\n)\nproj size before  128\nproj op ???  128\nvertex type conv1x1-bn-relu  size to 128\n128\nvertex type conv3x3-bn-relu  size to 128\n128\nproj op size to  128\nOp key vertex_2  to out shapes 128\nvertex type conv1x1-bn-relu  size to 128\n128\nvertex type conv3x3-bn-relu  size to 128\n128\nproj op size to  51\nOp key vertex_3  to out shapes 128\nvertex type conv1x1-bn-relu  size to 128\n128\nvertex type conv3x3-bn-relu  size to 128\n128\nproj op size to  51\nOp key vertex_4  to out shapes 128\nvertex type conv1x1-bn-relu  size to 128\n128\nvertex type conv3x3-bn-relu  size to 128\n128\nproj op size to  51\nOp key vertex_5  to out shapes 128\nvertex type conv1x1-bn-relu  size to 128\n128\nvertex type conv3x3-bn-relu  size to 128\n128\nproj op size to  51\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [256, 128, 128, 128, 128, 128, 256]\n",
      "Op key vertex_1  to out shapes 128\nMixedVertex(\n  (proj_ops): ModuleList(\n    (0): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n  )\n  (ops): ModuleDict(\n    (conv1x1-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (conv3x3-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (maxpool3x3): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n  )\n)\nproj size before  128\nproj op ???  128\nvertex type conv1x1-bn-relu  size to 128\n128\nvertex type conv3x3-bn-relu  size to 128\n128\nproj op size to  128\nOp key vertex_2  to out shapes 128\nvertex type conv1x1-bn-relu  size to 128\n128\nvertex type conv3x3-bn-relu  size to 128\n128\nproj op size to  51\nOp key vertex_3  to out shapes 128\nvertex type conv1x1-bn-relu  size to 128\n128\nvertex type conv3x3-bn-relu  size to 128\n128\nproj op size to  51\nOp key vertex_4  to out shapes 128\nvertex type conv1x1-bn-relu  size to 128\n128\nvertex type conv3x3-bn-relu  size to 128\n128\nproj op size to  51\nOp key vertex_5  to out shapes 128\nvertex type conv1x1-bn-relu  size to 128\n128\nvertex type conv3x3-bn-relu  size to 128\n128\nproj op size to  51\nchange spec for stack1\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [256, 256, 256, 256, 256, 256, 512]\n",
      "Op key vertex_1  to out shapes 256\nMixedVertex(\n  (proj_ops): ModuleList(\n    (0): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n  )\n  (ops): ModuleDict(\n    (conv1x1-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (conv3x3-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (maxpool3x3): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n  )\n)\nproj size before  256\nproj op ???  256\nvertex type conv1x1-bn-relu  size to 256\n256\nvertex type conv3x3-bn-relu  size to 256\n256\nproj op size to  256\nOp key vertex_2  to out shapes 256\nvertex type conv1x1-bn-relu  size to 256\n256\nvertex type conv3x3-bn-relu  size to 256\n256\nproj op size to  103\nOp key vertex_3  to out shapes 256\nvertex type conv1x1-bn-relu  size to 256\n256\nvertex type conv3x3-bn-relu  size to 256\n256\nproj op size to  102\nOp key vertex_4  to out shapes 256\nvertex type conv1x1-bn-relu  size to 256\n256\nvertex type conv3x3-bn-relu  size to 256\n256\nproj op size to  102\nOp key vertex_5  to out shapes 256\nvertex type conv1x1-bn-relu  size to 256\n256\nvertex type conv3x3-bn-relu  size to 256\n256\nproj op size to  102\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [512, 256, 256, 256, 256, 256, 512]\n",
      "Op key vertex_1  to out shapes 256\nMixedVertex(\n  (proj_ops): ModuleList(\n    (0): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n  )\n  (ops): ModuleDict(\n    (conv1x1-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (conv3x3-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (maxpool3x3): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n  )\n)\nproj size before  256\nproj op ???  256\nvertex type conv1x1-bn-relu  size to 256\n256\nvertex type conv3x3-bn-relu  size to 256\n256\nproj op size to  256\nOp key vertex_2  to out shapes 256\nvertex type conv1x1-bn-relu  size to 256\n256\nvertex type conv3x3-bn-relu  size to 256\n256\nproj op size to  103\nOp key vertex_3  to out shapes 256\nvertex type conv1x1-bn-relu  size to 256\n256\nvertex type conv3x3-bn-relu  size to 256\n256\nproj op size to  102\nOp key vertex_4  to out shapes 256\nvertex type conv1x1-bn-relu  size to 256\n256\nvertex type conv3x3-bn-relu  size to 256\n256\nproj op size to  102\nOp key vertex_5  to out shapes 256\nvertex type conv1x1-bn-relu  size to 256\n256\nvertex type conv3x3-bn-relu  size to 256\n256\nproj op size to  102\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [512, 256, 256, 256, 256, 256, 512]\n",
      "Op key vertex_1  to out shapes 256\nMixedVertex(\n  (proj_ops): ModuleList(\n    (0): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n  )\n  (ops): ModuleDict(\n    (conv1x1-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (conv3x3-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (maxpool3x3): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n  )\n)\nproj size before  256\nproj op ???  256\nvertex type conv1x1-bn-relu  size to 256\n256\nvertex type conv3x3-bn-relu  size to 256\n256\nproj op size to  256\nOp key vertex_2  to out shapes 256\nvertex type conv1x1-bn-relu  size to 256\n256\nvertex type conv3x3-bn-relu  size to 256\n256\nproj op size to  103\nOp key vertex_3  to out shapes 256\nvertex type conv1x1-bn-relu  size to 256\n256\nvertex type conv3x3-bn-relu  size to 256\n256\nproj op size to  102\nOp key vertex_4  to out shapes 256\nvertex type conv1x1-bn-relu  size to 256\n256\nvertex type conv3x3-bn-relu  size to 256\n256\nproj op size to  102\nOp key vertex_5  to out shapes 256\nvertex type conv1x1-bn-relu  size to 256\n256\nvertex type conv3x3-bn-relu  size to 256\n256\nproj op size to  102\nchange spec for stack2\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [512, 512, 512, 512, 512, 512, 1024]\n",
      "Op key vertex_1  to out shapes 512\nMixedVertex(\n  (proj_ops): ModuleList(\n    (0): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n  )\n  (ops): ModuleDict(\n    (conv1x1-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (conv3x3-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (maxpool3x3): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n  )\n)\nproj size before  512\nproj op ???  512\nvertex type conv1x1-bn-relu  size to 512\n512\nvertex type conv3x3-bn-relu  size to 512\n512\nproj op size to  512\nOp key vertex_2  to out shapes 512\nvertex type conv1x1-bn-relu  size to 512\n512\nvertex type conv3x3-bn-relu  size to 512\n512\nproj op size to  205\nOp key vertex_3  to out shapes 512\nvertex type conv1x1-bn-relu  size to 512\n512\nvertex type conv3x3-bn-relu  size to 512\n512\nproj op size to  205\nOp key vertex_4  to out shapes 512\nvertex type conv1x1-bn-relu  size to 512\n512\nvertex type conv3x3-bn-relu  size to 512\n512\nproj op size to  205\nOp key vertex_5  to out shapes 512\nvertex type conv1x1-bn-relu  size to 512\n512\nvertex type conv3x3-bn-relu  size to 512\n512\nproj op size to  204\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [1024, 512, 512, 512, 512, 512, 1024]\n",
      "Op key vertex_1  to out shapes 512\nMixedVertex(\n  (proj_ops): ModuleList(\n    (0): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n  )\n  (ops): ModuleDict(\n    (conv1x1-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (conv3x3-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (maxpool3x3): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n  )\n)\nproj size before  512\nproj op ???  512\nvertex type conv1x1-bn-relu  size to 512\n512\nvertex type conv3x3-bn-relu  size to 512\n512\nproj op size to  512\nOp key vertex_2  to out shapes 512\nvertex type conv1x1-bn-relu  size to 512\n512\nvertex type conv3x3-bn-relu  size to 512\n512\nproj op size to  205\nOp key vertex_3  to out shapes 512\nvertex type conv1x1-bn-relu  size to 512\n512\nvertex type conv3x3-bn-relu  size to 512\n512\nproj op size to  205\nOp key vertex_4  to out shapes 512\nvertex type conv1x1-bn-relu  size to 512\n512\nvertex type conv3x3-bn-relu  size to 512\n512\nproj op size to  205\nOp key vertex_5  to out shapes 512\nvertex type conv1x1-bn-relu  size to 512\n512\nvertex type conv3x3-bn-relu  size to 512\n512\nproj op size to  204\norder dict odict_keys(['vertex_1', 'vertex_2', 'vertex_3', 'vertex_4', 'vertex_5', 'output'])\nINFO:tensorflow:vertex_channels: [1024, 512, 512, 512, 512, 512, 1024]\n",
      "Op key vertex_1  to out shapes 512\nMixedVertex(\n  (proj_ops): ModuleList(\n    (0): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n  )\n  (ops): ModuleDict(\n    (conv1x1-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (conv3x3-bn-relu): DynamicReLUConvBN(\n      (relu): ReLU()\n      (conv): DynamicConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n      (channel_drop): ChannelDropout()\n    )\n    (maxpool3x3): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n  )\n)\nproj size before  512\nproj op ???  512\nvertex type conv1x1-bn-relu  size to 512\n512\nvertex type conv3x3-bn-relu  size to 512\n512\nproj op size to  512\nOp key vertex_2  to out shapes 512\nvertex type conv1x1-bn-relu  size to 512\n512\nvertex type conv3x3-bn-relu  size to 512\n512\nproj op size to  205\nOp key vertex_3  to out shapes 512\nvertex type conv1x1-bn-relu  size to 512\n512\nvertex type conv3x3-bn-relu  size to 512\n512\nproj op size to  205\nOp key vertex_4  to out shapes 512\nvertex type conv1x1-bn-relu  size to 512\n512\nvertex type conv3x3-bn-relu  size to 512\n512\nproj op size to  205\nOp key vertex_5  to out shapes 512\nvertex type conv1x1-bn-relu  size to 512\n512\nvertex type conv3x3-bn-relu  size to 512\n512\nproj op size to  204\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(spec_2)\n",
    "model_search.change_model_spec(spec_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "torch.Size([8, 128, 32, 32])\n51\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "stem = model_search.stem(x)\n",
    "print(stem.size())\n",
    "kky = 'vertex_2'\n",
    "layer0 = model_search.stacks['stack0']['module0']\n",
    "proj_op = layer0.op[kky].proj_ops[0]\n",
    "print(proj_op.current_outsize)\n",
    "\n",
    "# print(layer0.op['vertex_5'].proj_ops[0](stem).size())\n",
    "# print(layer0.op['vertex_5'](stem))\n",
    "# print(layer0(stem))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# y2 = model_search(x)\n",
    "# print(y2[0])\n",
    "# print(y[0] - y[2])\n",
    "\n",
    "# for _y in y:\n",
    "    # print(y.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[ 0.3450, -0.0704, -0.1695,  0.0178,  0.0487,  0.0056, -0.3518, -0.1745,\n          0.2760, -0.1088],\n        [ 0.2210,  0.0211, -0.2112,  0.1045,  0.1881,  0.0228, -0.2952, -0.0650,\n          0.2683,  0.0102],\n        [ 0.0957,  0.1265, -0.2533,  0.0606,  0.1759, -0.2230, -0.1577, -0.0533,\n          0.3005,  0.0404],\n        [ 0.4161,  0.0423, -0.2323, -0.0907, -0.1212,  0.0458, -0.2781,  0.2126,\n          0.0769, -0.1699],\n        [ 0.1716, -0.0439, -0.2435,  0.0354, -0.0701, -0.1199, -0.1195, -0.1251,\n          0.1916, -0.1568],\n        [ 0.2207,  0.1559, -0.1929,  0.1457, -0.0711, -0.0203, -0.2858, -0.2412,\n          0.2389, -0.1918],\n        [ 0.1525,  0.0487, -0.1349, -0.1123,  0.0887, -0.0552, -0.2153,  0.2390,\n          0.1475, -0.0072],\n        [ 0.1708, -0.1266, -0.1768, -0.0363,  0.1934, -0.2910, -0.2259,  0.0252,\n          0.3739, -0.0819]], grad_fn=<SubBackward0>)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "out = model1(x)[0] - model2(x)[0]\n",
    "print(out)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[0 1 1 1 1 1 1]\n [0 0 1 1 1 1 1]\n [0 0 0 1 1 1 1]\n [0 0 0 0 1 1 1]\n [0 0 0 0 0 1 1]\n [0 0 0 0 0 0 1]\n [0 0 0 0 0 0 0]]\nINFO:tensorflow:vertex_channels: [128, 52, 51, 51, 51, 51, 256]\n",
      "INFO:tensorflow:vertex_channels: [256, 52, 51, 51, 51, 51, 256]\n",
      "INFO:tensorflow:vertex_channels: [256, 52, 51, 51, 51, 51, 256]\n",
      "INFO:tensorflow:vertex_channels: [256, 103, 103, 102, 102, 102, 512]\n",
      "INFO:tensorflow:vertex_channels: [512, 103, 103, 102, 102, 102, 512]\n",
      "INFO:tensorflow:vertex_channels: [512, 103, 103, 102, 102, 102, 512]\n",
      "INFO:tensorflow:vertex_channels: [512, 205, 205, 205, 205, 204, 1024]\n",
      "INFO:tensorflow:vertex_channels: [1024, 205, 205, 205, 205, 204, 1024]\n",
      "INFO:tensorflow:vertex_channels: [1024, 205, 205, 205, 205, 204, 1024]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "[autoreload of search_policies.cnn.search_space.nasbench101.model_search failed: Traceback (most recent call last):\n  File \"/home/yukaiche/anaconda3/envs/pytorch-latest/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n    superreload(m, reload, self.old_objects)\n  File \"/home/yukaiche/anaconda3/envs/pytorch-latest/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 378, in superreload\n    module = reload(module)\n  File \"/home/yukaiche/anaconda3/envs/pytorch-latest/lib/python3.6/imp.py\", line 315, in reload\n    return importlib.reload(module)\n  File \"/home/yukaiche/anaconda3/envs/pytorch-latest/lib/python3.6/importlib/__init__.py\", line 166, in reload\n    _bootstrap._exec(spec, module)\n  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n  File \"/home/yukaiche/pycharm/automl/search_policies/cnn/nasbench101/model_search.py\", line 10, in <module>\n    from .operations import conv_bn_relu, OPS, SEARCH_OPS\nImportError: cannot import name 'SEARCH_OPS'\n]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# model_search.stacks['stack0']['module0'].dag\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nasbench.lib import graph_util\n",
    "full = 1 - np.tril(np.ones_like(spec_1.matrix) )\n",
    "full_hash = graph_util.hash_module(full, spec_1.ops)\n",
    "full_spec = ModelSpec(full, spec_1.ops)\n",
    "full_spec._prune()\n",
    "print(full_spec.matrix)\n",
    "\n",
    "full_model = NasbenchNetOriginal(input_channels, full_spec)\n",
    "# nasbench.query(full_spec)\n",
    "# nasbench.query_hash(full_hash)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[[[-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n            0.0000e+00, -0.0000e+00],\n          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n           -0.0000e+00, -0.0000e+00],\n          ...,\n          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n           -0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n           -0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00]],\n\n         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00, -0.0000e+00],\n          [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00, -0.0000e+00],\n          ...,\n          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n           -0.0000e+00,  0.0000e+00],\n          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n           -0.0000e+00, -0.0000e+00]],\n\n         [[ 2.6606e+00, -1.8413e+00, -4.5564e+00,  ..., -7.9628e-01,\n            1.7808e+00,  1.6850e+00],\n          [ 9.3348e-01,  1.0377e-01,  3.3292e-01,  ..., -1.2201e+00,\n           -1.4720e-01, -2.3414e-01],\n          [ 3.8806e+00, -3.2980e+00, -2.4671e+00,  ...,  3.4043e+00,\n           -3.8494e+00,  6.2659e-01],\n          ...,\n          [-1.6816e+00, -7.8637e-01,  6.0322e-03,  ..., -1.1372e+00,\n            4.1006e-01,  2.6142e+00],\n          [ 1.1413e+00, -1.5779e+00, -3.7817e+00,  ..., -7.1949e-01,\n           -9.2168e-01, -6.2839e-01],\n          [ 9.3478e-02, -1.1313e+00,  1.6387e+00,  ..., -2.5606e+00,\n           -5.3552e-01,  4.8535e-01]]],\n\n\n        [[[-6.8065e+00,  3.3706e-01, -4.5988e+00,  ..., -1.2530e+00,\n            1.2197e+00, -3.2355e+00],\n          [ 3.3250e+00, -2.0167e+00,  2.0770e+00,  ...,  2.6417e-01,\n            2.8984e+00, -1.5467e+00],\n          [ 1.7613e+00, -1.7306e-01, -1.2969e-01,  ...,  1.0612e+00,\n           -1.3606e+00,  2.8175e+00],\n          ...,\n          [ 1.7216e+00,  3.6200e+00, -1.9324e+00,  ...,  3.3778e-01,\n            3.4743e-01,  1.4209e+00],\n          [-2.1844e+00, -4.4079e+00,  2.3208e+00,  ..., -3.7140e-01,\n            2.8497e+00,  1.8030e+00],\n          [ 1.2536e+00,  8.2118e-01,  1.8068e+00,  ..., -1.4572e+00,\n           -2.7518e+00, -1.9783e+00]],\n\n         [[-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n           -0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n            0.0000e+00, -0.0000e+00],\n          ...,\n          [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n           -0.0000e+00, -0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00, -0.0000e+00]],\n\n         [[ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          ...,\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n            0.0000e+00, -0.0000e+00],\n          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n           -0.0000e+00, -0.0000e+00]]],\n\n\n        [[[-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n           -0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n           -0.0000e+00, -0.0000e+00],\n          ...,\n          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n           -0.0000e+00, -0.0000e+00],\n          [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n           -0.0000e+00, -0.0000e+00],\n          [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00]],\n\n         [[ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n           -0.0000e+00, -0.0000e+00],\n          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n            0.0000e+00, -0.0000e+00],\n          ...,\n          [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n           -0.0000e+00, -0.0000e+00],\n          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00]],\n\n         [[ 1.8800e+00, -4.0202e-01,  8.8689e-01,  ..., -3.5375e+00,\n            7.7759e-01,  6.8101e-01],\n          [-3.6526e-01, -1.7317e+00,  1.3120e+00,  ..., -6.0840e-01,\n           -1.4307e+00,  9.5901e-01],\n          [-1.2311e+00,  5.4551e-01, -3.0092e+00,  ..., -7.4640e-02,\n            2.1246e+00,  7.9588e-02],\n          ...,\n          [ 5.3829e+00, -2.2791e+00, -5.9729e-01,  ...,  1.6939e+00,\n           -9.1515e-01,  2.6346e+00],\n          [-3.5762e+00,  1.3684e-01,  1.4085e+00,  ..., -1.9619e+00,\n           -3.1877e-01, -2.2825e+00],\n          [-1.5304e+00,  3.3954e+00,  3.7647e-01,  ..., -2.0466e+00,\n           -3.4028e-01,  6.7784e-02]]],\n\n\n        ...,\n\n\n        [[[ 1.1236e+00,  4.4577e+00,  2.0041e+00,  ...,  5.5717e-01,\n            4.8168e-01, -1.6823e+00],\n          [-1.7420e+00, -2.4816e+00,  5.0305e-01,  ..., -4.4643e+00,\n           -1.2546e+00,  3.0201e-01],\n          [ 1.1070e-01, -4.5808e-01,  1.5350e+00,  ...,  6.6467e-02,\n           -1.7991e+00,  2.4978e-01],\n          ...,\n          [-2.7991e+00, -4.5061e-02,  1.5686e+00,  ..., -1.9153e+00,\n           -1.1801e+00,  1.3886e+00],\n          [ 2.1922e+00,  4.5539e-01,  2.7976e-01,  ..., -1.8108e+00,\n           -1.3534e+00, -1.0372e+00],\n          [ 1.4275e+00,  3.7105e-01,  2.9016e-02,  ...,  8.3740e-01,\n            2.4553e+00, -8.7041e-01]],\n\n         [[ 1.0307e+00,  9.9971e-01, -9.6251e-01,  ...,  2.7714e+00,\n            1.3531e+00,  1.7510e+00],\n          [-7.2837e-01, -2.8374e-02, -9.0262e-01,  ..., -3.0579e+00,\n           -4.5106e-01, -1.2110e+00],\n          [-1.2764e+00, -1.5096e+00, -2.0167e-02,  ..., -2.5146e+00,\n            1.3097e+00, -1.9361e+00],\n          ...,\n          [ 1.6886e+00, -2.2725e+00, -1.9116e+00,  ..., -2.1148e-01,\n            1.4970e+00, -1.4409e+00],\n          [-1.8055e-01, -5.5597e-01,  1.6090e+00,  ..., -3.6725e+00,\n           -4.6811e+00, -9.3901e-01],\n          [-4.0706e+00, -1.3409e+00,  9.7691e-01,  ...,  5.6526e-01,\n           -1.4658e+00, -1.3028e+00]],\n\n         [[-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n           -0.0000e+00,  0.0000e+00],\n          [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00, -0.0000e+00],\n          ...,\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n           -0.0000e+00,  0.0000e+00],\n          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00,  0.0000e+00]]],\n\n\n        [[[-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n           -0.0000e+00, -0.0000e+00],\n          [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00, -0.0000e+00],\n          [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00, -0.0000e+00],\n          ...,\n          [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n           -0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n           -0.0000e+00,  0.0000e+00]],\n\n         [[-2.1036e+00,  2.9386e+00,  7.2497e-01,  ...,  1.7753e-01,\n           -1.0636e-01,  4.8787e-01],\n          [-3.4924e+00,  3.6290e-01,  9.1985e-01,  ..., -1.3089e+00,\n           -1.2553e+00,  3.6359e-01],\n          [-3.9462e+00, -3.1767e-01,  1.4217e+00,  ...,  4.8339e-01,\n            5.1724e-01,  9.6995e-01],\n          ...,\n          [ 1.5275e+00, -4.0457e-01, -1.3678e+00,  ...,  6.3464e-01,\n           -1.0619e+00, -4.0782e+00],\n          [ 9.0198e-01, -1.2071e-01, -4.5070e+00,  ..., -2.5234e-01,\n           -8.6100e-01,  7.8387e-01],\n          [-3.1832e-01, -7.7404e-01,  2.2608e+00,  ...,  1.3658e+00,\n           -1.5781e+00, -3.3694e-01]],\n\n         [[ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n            0.0000e+00, -0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00, -0.0000e+00],\n          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n           -0.0000e+00, -0.0000e+00],\n          ...,\n          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n           -0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n            0.0000e+00, -0.0000e+00]]],\n\n\n        [[[ 4.6791e+00, -4.2370e-04,  4.2555e+00,  ...,  7.3260e-01,\n            6.2514e-01,  2.8284e+00],\n          [-3.7687e+00,  8.1044e-01,  4.1212e+00,  ..., -3.7617e+00,\n           -3.3181e+00,  2.8896e+00],\n          [-1.2453e+00, -3.1193e-01, -1.1835e+00,  ..., -1.9241e+00,\n            1.0563e+00,  2.2575e+00],\n          ...,\n          [ 2.9282e+00,  6.2070e-01, -2.6365e+00,  ..., -2.7608e+00,\n           -1.7261e+00,  6.1776e-01],\n          [-2.4366e-01, -3.5351e-01,  9.9418e-01,  ..., -1.3683e+00,\n           -1.2141e+00,  1.1522e+00],\n          [ 1.8894e-01, -4.3062e-01, -4.4025e+00,  ..., -9.9646e-01,\n           -3.0680e+00, -1.0999e+00]],\n\n         [[-2.6859e-01,  2.4893e+00,  1.7033e+00,  ..., -2.3268e+00,\n           -2.3311e+00, -1.2803e+00],\n          [ 3.2576e-01, -1.3525e+00,  8.1881e-02,  ...,  1.2649e+00,\n            1.2250e-01,  2.9520e+00],\n          [-3.5612e+00,  1.4106e+00,  3.1271e-01,  ..., -6.4371e-02,\n            5.0599e+00,  1.6312e+00],\n          ...,\n          [-1.7207e-01, -1.3558e+00,  7.7869e-01,  ...,  1.2991e+00,\n            2.3580e+00, -1.4689e+00],\n          [-7.6419e-01,  6.4204e-01, -1.3321e-01,  ..., -9.5787e-01,\n           -3.0613e+00,  1.8193e+00],\n          [ 3.7570e+00,  8.6641e-01, -3.5431e+00,  ...,  1.3755e+00,\n            8.2907e-01,  1.2699e-01]],\n\n         [[-9.3993e-01, -1.2020e+00, -2.7493e+00,  ...,  5.2928e-01,\n            1.8223e-01, -8.3399e-01],\n          [ 2.6507e-01, -1.3670e-01,  7.4052e-03,  ...,  6.8187e-01,\n           -1.0538e+00,  4.8915e-01],\n          [ 2.3811e-01, -2.6370e+00,  2.2258e+00,  ...,  7.0278e-02,\n           -1.5365e+00,  1.4232e+00],\n          ...,\n          [-2.2705e+00,  2.1591e+00, -1.8140e+00,  ...,  5.9272e-01,\n            1.1462e+00, -8.7368e-01],\n          [-8.0207e-01, -4.0501e+00,  3.1108e+00,  ...,  3.3776e-01,\n           -9.1726e-01,  3.1382e-01],\n          [ 5.0031e-01,  5.5025e-01, -1.1765e+00,  ...,  1.6067e+00,\n            2.0595e+00, -1.1080e+00]]]])\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "[autoreload of search_policies.cnn.search_space.nasbench101.operations failed: Traceback (most recent call last):\n  File \"/home/yukaiche/anaconda3/envs/pytorch-latest/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n    superreload(m, reload, self.old_objects)\n  File \"/home/yukaiche/anaconda3/envs/pytorch-latest/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 378, in superreload\n    module = reload(module)\n  File \"/home/yukaiche/anaconda3/envs/pytorch-latest/lib/python3.6/imp.py\", line 315, in reload\n    return importlib.reload(module)\n  File \"/home/yukaiche/anaconda3/envs/pytorch-latest/lib/python3.6/importlib/__init__.py\", line 166, in reload\n    _bootstrap._exec(spec, module)\n  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n  File \"<frozen importlib._bootstrap_external>\", line 781, in get_code\n  File \"<frozen importlib._bootstrap_external>\", line 741, in source_to_code\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n  File \"/home/yukaiche/pycharm/automl/search_policies/cnn/nasbench101/operations.py\", line 53\n    def conv_bn_relu_ws_v1(kernel_size, original_output_size, input_size, output_size):\n                                                                                      ^\nIndentationError: expected an indented block\n]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "xx = F.dropout2d(x, 0.5, training=True)\n",
    "\n",
    "print(xx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# testing the shuffle channel\n",
    "def channel_shuffle(x, groups):\n",
    "    batchsize, num_channels, height, width = x.data.size()\n",
    "\n",
    "    channels_per_group = num_channels // groups\n",
    "    \n",
    "    # reshape\n",
    "    x = x.view(batchsize, groups, \n",
    "        channels_per_group, height, width)\n",
    "\n",
    "    # transpose\n",
    "    # - contiguous() required if transpose() is used before view().\n",
    "    #   See https://github.com/pytorch/pytorch/issues/764\n",
    "    x = torch.transpose(x, 1, 2).contiguous()\n",
    "\n",
    "    # flatten\n",
    "    x = x.view(batchsize, -1, height, width)\n",
    "\n",
    "    return x\n",
    "\n",
    "test_x = np.arange(1, 9)\n",
    "test_x = torch.from_numpy(test_x).view(1, 8, 1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[[[1]],\n\n         [[2]],\n\n         [[3]],\n\n         [[4]],\n\n         [[5]],\n\n         [[6]],\n\n         [[7]],\n\n         [[8]]]])\ntensor([[[[1]],\n\n         [[3]],\n\n         [[5]],\n\n         [[7]],\n\n         [[2]],\n\n         [[4]],\n\n         [[6]],\n\n         [[8]]]])\ntensor([[[[1]],\n\n         [[3]],\n\n         [[5]],\n\n         [[7]],\n\n         [[2]],\n\n         [[4]],\n\n         [[6]],\n\n         [[8]]]])\ntensor([[[[1]],\n\n         [[3]],\n\n         [[5]],\n\n         [[7]],\n\n         [[2]],\n\n         [[4]],\n\n         [[6]],\n\n         [[8]]]])\ntensor([[[[1]],\n\n         [[3]],\n\n         [[5]],\n\n         [[7]],\n\n         [[2]],\n\n         [[4]],\n\n         [[6]],\n\n         [[8]]]])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(test_x)\n",
    "print(channel_shuffle(test_x, 4))\n",
    "print(channel_shuffle(test_x, 4))\n",
    "print(channel_shuffle(test_x, 4))\n",
    "print(channel_shuffle(test_x, 4))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch1.0",
   "language": "python",
   "display_name": "pytorch-latest"
  },
  "name": "demo.ipynb",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}